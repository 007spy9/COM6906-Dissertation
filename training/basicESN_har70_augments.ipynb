{
 "cells": [
  {
   "cell_type": "code",
   "id": "bf190cd95bbda6c9",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-07T16:31:27.354008Z",
     "start_time": "2024-08-07T16:31:26.887763Z"
    }
   },
   "source": [
    "import collections\n",
    "# Prepare paths to local utilities\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T16:31:27.369535Z",
     "start_time": "2024-08-07T16:31:27.355516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "is_kaggle = (os.environ.get(\"PWD\", \"\") == \"/kaggle/working\")\n",
    "print(f\"Are we running in Kaggle? {is_kaggle}\")"
   ],
   "id": "f95435316e69eef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are we running in Kaggle? False\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T16:31:41.346951Z",
     "start_time": "2024-08-07T16:31:27.371036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not is_kaggle:\n",
    "    models_path = os.path.abspath(os.path.join('..', 'model'))\n",
    "    utils_path = os.path.abspath(os.path.join('..', 'util'))\n",
    "    sys.path.append(models_path)\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "    from download.DataDownloader import DataDownloader\n",
    "    from collect.DataframeCollector import DataframeCollector\n",
    "    from collect.TestSetSplitter import TestSetSplitter\n",
    "    from collect.DatasetPreparation import DatasetPreparation\n",
    "    from processing.DataPreprocessor import DataPreprocessor\n",
    "    from reservoir.BasicESNCuda import BasicESNCuda as BasicESN\n",
    "    from reservoir.ESNUtil import generate_input_weights\n",
    "\n",
    "else:\n",
    "    from datadownloader.datadownloader import DataDownloader\n",
    "    from dataframecollector.dataframecollector import DataframeCollector\n",
    "    from testsetsplitter.testsetsplitter import TestSetSplitter\n",
    "    from datasetpreparation.datasetpreparation import DatasetPreparation\n",
    "    from datapreprocessor.datapreprocessor import DataPreprocessor\n",
    "    from basicesncuda.basicesncuda import BasicESNCuda as BasicESN\n",
    "    from esnutil.esnutil import generate_input_weights"
   ],
   "id": "7c2fda8c0f1dbaf8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T16:31:41.941263Z",
     "start_time": "2024-08-07T16:31:41.348361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import contextlib\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    '''\n",
    "    Context manager to patch joblib to report into tqdm progress bar given as argument\n",
    "    :param tqdm_object: The tqdm progress bar\n",
    "    '''\n",
    "\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-07T16:31:41.942767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_preparation = DatasetPreparation()\n",
    "\n",
    "input_features = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
    "output_features = ['label']\n",
    "\n",
    "data_preparation.prepare_dataset('har70plus', input_features, output_features)"
   ],
   "id": "534e71f8d3f6432a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n",
      "Discovered  18  csv files in  E:\\PyCharm\\COM6906-Dissertation\\data\\har70plus\n",
      "Loading the csv files into dataframes\n",
      "Loaded  18  dataframes\n",
      "Concatenating the dataframes\n",
      "Data shape:  [(103860, 9), (131367, 9), (116413, 9), (150758, 9), (87006, 9), (122714, 9), (120125, 9), (130494, 9), (121763, 9), (122061, 9), (128063, 9), (119310, 9), (123599, 9), (101510, 9), (153517, 9), (138278, 9), (147045, 9), (141714, 9)]\n",
      "Number of frames in training set: 17\n",
      "Number of frames in validation set: 17\n",
      "Number of frames in testing set: 18\n",
      "X_train shape: (1357646, 6), Y_train shape: (1357646, 1)\n",
      "X_val shape: (339404, 6), Y_val shape: (339404, 1)\n",
      "X_test shape: (562547, 6), Y_test shape: (562547, 1)\n",
      "Y_train encoded shape: (1357646, 7)\n",
      "Y_val encoded shape: (339404, 7)\n",
      "Y_test encoded shape: (562547, 7)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_scaled, y_train_encoded = data_preparation.get_preprocessed_data('train')\n",
    "X_val_scaled, y_val_encoded = data_preparation.get_preprocessed_data('val')\n",
    "X_test_scaled, y_test_encoded = data_preparation.get_preprocessed_data('test')"
   ],
   "id": "449cdf48439614e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "data_preprocessor = DataPreprocessor()\n",
    "\n",
    "# The data preprocessor object provides access to different data preprocessing methods\n",
    "# The available methods are:\n",
    "# - buffered_windows(window_size, x, y)\n",
    "# - exponential_moving_average(alpha, x, y)\n",
    "# - fourier_smoothing(x, threshold)\n",
    "# - pipeline(step_names, x, y)\n",
    "# - get_available_steps()"
   ],
   "id": "6a46491ad76dd7c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# As a test, we will start by taking the optimal hyperparameter set from the basicESN testing and see whether this needs to be adjusted once the data is preprocessed\n",
    "\n",
    "# The optimal hyperparameters were:\n",
    "n_neurons = 500\n",
    "density = 0.2\n",
    "leakage = 0.8\n",
    "spectral_radius = 0.999\n",
    "gamma = 0.999\n",
    "sparsity = 0.8\n",
    "input_weight_type = 'uniform'\n",
    "\n",
    "# We will first try using each preprocessing method separately to see if any of them improve the performance, and then attempt a few pipelines to see if a combination of methods can improve the performance"
   ],
   "id": "26f8312b9537fc54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "run_windows_optimal = True",
   "id": "ed3177014058ebc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# First, we will try the buffered_windows method\n",
    "\n",
    "if run_windows_optimal:\n",
    "    window_sizes = [10, 50, 100, 500, 1000]\n",
    "    \n",
    "    window_scores = []\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        x_train_windowed, y_train_windowed = data_preprocessor.buffered_windows(window_size, X_train_scaled, y_train_encoded)\n",
    "        x_val_windowed, y_val_windowed = data_preprocessor.buffered_windows(window_size, X_val_scaled, y_val_encoded)\n",
    "        x_test_windowed, y_test_windowed = data_preprocessor.buffered_windows(window_size, X_test_scaled, y_test_encoded)\n",
    "        \n",
    "        basic_esn = BasicESN(n_neurons=n_neurons, density=density, leakage=leakage, spectral_radius=spectral_radius, gamma=gamma, sparsity=sparsity, input_weight_type=input_weight_type)\n",
    "        \n",
    "        basic_esn.fit(x_train_windowed, y_train_windowed, x_val=x_val_windowed, y_val=y_val_windowed)\n",
    "        \n",
    "        y_pred = basic_esn.forward(x_test_windowed)\n",
    "        \n",
    "        # Before we can score the model, we need to decode the one-hot encoded labels\n",
    "        # As we are using windowed data, we first need to reshape the data from (n_samples//window_size, n_classes * window_size) to (n_samples, n_classes)\n",
    "        # And then we need to pass the reshaped data through the inverse_transform of data_preparation.get_encoder()\n",
    "        y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[1] // window_size)\n",
    "        y_test_reshaped = y_test_windowed.reshape(-1, y_test_windowed.shape[1] // window_size)\n",
    "        \n",
    "        y_pred_decoded = data_preparation.get_encoder().inverse_transform(y_pred_reshaped)\n",
    "        y_test_decoded = data_preparation.get_encoder().inverse_transform(y_test_reshaped)\n",
    "        \n",
    "        # Calculate the NMRSE score\n",
    "        nrmse = np.sqrt(mean_squared_error(y_test_decoded, y_pred_decoded)) / (y_test_decoded.max() - y_test_decoded.min())\n",
    "        \n",
    "        window_scores.append({'window_size': window_size, 'nmrse': nrmse})\n",
    "        \n",
    "else:\n",
    "    window_scores = []"
   ],
   "id": "35ef017b6334df76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "print(window_scores)",
   "id": "bf8b2e77e556aa32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's plot the results to see if there is a clear winner\n",
    "sizes = [score['window_size'] for score in window_scores]\n",
    "nmrse = [score['nmrse'] for score in window_scores]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(sizes, nmrse, marker='o')\n",
    "plt.xlabel('Window size')\n",
    "plt.ylabel('NMRSE')\n",
    "plt.title('NMRSE scores for different window sizes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "39d1e950f510d3c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the best window size\n",
    "best_window_optimal = window_scores[np.argmin(nmrse)]['window_size']\n",
    "\n",
    "print(f\"Best Window Size: {best_window_optimal}\")"
   ],
   "id": "4948115a6dfed401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "run_emas_optimal = True",
   "id": "99aa6bfa8de315a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we will try the exponential_moving_average method\n",
    "\n",
    "if run_emas_optimal:\n",
    "    alphas = [0.001, 0.01, 0.1, 0.5, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "    \n",
    "    ema_scores = []\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        x_train_ema, y_train_ema = data_preprocessor.exponential_moving_average(alpha, X_train_scaled, y_train_encoded)\n",
    "        x_val_ema, y_val_ema = data_preprocessor.exponential_moving_average(alpha, X_val_scaled, y_val_encoded)\n",
    "        x_test_ema, y_test_ema = data_preprocessor.exponential_moving_average(alpha, X_test_scaled, y_test_encoded)\n",
    "        \n",
    "        basic_esn = BasicESN(n_neurons=n_neurons, density=density, leakage=leakage, spectral_radius=spectral_radius, gamma=gamma, sparsity=sparsity, input_weight_type=input_weight_type)\n",
    "        \n",
    "        basic_esn.fit(x_train_ema, y_train_ema, x_val=x_val_ema, y_val=y_val_ema)\n",
    "        \n",
    "        y_pred = basic_esn.forward(x_test_ema)\n",
    "        \n",
    "        # Before we can score the model, we need to decode the one-hot encoded labels\n",
    "        y_pred_decoded = data_preparation.get_encoder().inverse_transform(y_pred)\n",
    "        y_test_decoded = data_preparation.get_encoder().inverse_transform(y_test_ema)\n",
    "        \n",
    "        # Calculate the NMRSE score\n",
    "        nrmse = np.sqrt(mean_squared_error(y_test_decoded, y_pred_decoded)) / (y_test_decoded.max() - y_test_decoded.min())\n",
    "        \n",
    "        ema_scores.append({'alpha': alpha, 'nmrse': nrmse})\n",
    "        \n",
    "else:\n",
    "    ema_scores = []"
   ],
   "id": "dcaebf32bdb81096",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's plot the results to see if there is a clear winner\n",
    "alphas = [score['alpha'] for score in ema_scores]\n",
    "nmrse = [score['nmrse'] for score in ema_scores]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(alphas, nmrse, marker='o')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('NMRSE')\n",
    "plt.title('NMRSE scores for different alpha values')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8addf2dcc58cb5d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the best alpha\n",
    "best_alpha_optimal = ema_scores[np.argmin(nmrse)]['alpha']\n",
    "\n",
    "print(f\"Best EMA Alpha: {best_alpha_optimal}\")"
   ],
   "id": "67f922305618a176",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "run_fourier_optimal = True",
   "id": "2c414c3b9f7f1d39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we will try the fourier_smoothing method\n",
    "\n",
    "if run_fourier_optimal:\n",
    "    thresholds = [1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    \n",
    "    fourier_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        x_train_fourier = data_preprocessor.fourier_smoothing(X_train_scaled, threshold)\n",
    "        x_val_fourier = data_preprocessor.fourier_smoothing(X_val_scaled, threshold)\n",
    "        x_test_fourier = data_preprocessor.fourier_smoothing(X_test_scaled, threshold)\n",
    "        \n",
    "        basic_esn = BasicESN(n_neurons=n_neurons, density=density, leakage=leakage, spectral_radius=spectral_radius, gamma=gamma, sparsity=sparsity, input_weight_type=input_weight_type)\n",
    "        \n",
    "        basic_esn.fit(x_train_fourier, y_train_encoded, x_val=x_val_fourier, y_val=y_val_encoded)\n",
    "        \n",
    "        y_pred = basic_esn.forward(x_test_fourier)\n",
    "        \n",
    "        # Before we can score the model, we need to decode the one-hot encoded labels\n",
    "        y_pred_decoded = data_preparation.get_encoder().inverse_transform(y_pred)\n",
    "        y_test_decoded = data_preparation.get_encoder().inverse_transform(y_test_encoded)\n",
    "        \n",
    "        # Calculate the NMRSE score\n",
    "        nrmse = np.sqrt(mean_squared_error(y_test_decoded, y_pred_decoded)) / (y_test_decoded.max() - y_test_decoded.min())\n",
    "        \n",
    "        fourier_scores.append({'threshold': threshold, 'nmrse': nrmse})\n",
    "        \n",
    "else:\n",
    "    fourier_scores = []"
   ],
   "id": "ce33bf10c91aed4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's plot the results to see if there is a clear winner\n",
    "thresholds = [score['threshold'] for score in fourier_scores]\n",
    "nmrse = [score['nmrse'] for score in fourier_scores]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(thresholds, nmrse, marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('NMRSE')\n",
    "plt.title('NMRSE scores for different threshold values')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "71692688e1185fcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the best threshold\n",
    "best_threshold_optimal = fourier_scores[np.argmin(nmrse)]['threshold']\n",
    "\n",
    "print(f\"Best Fourier Threshold: {best_threshold_optimal}\")"
   ],
   "id": "a934e854ab1840ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# From our basicESN testing, we know that there are some ranges of suboptimal hyperparameters, so these can be excluded from the search space to save time\n",
    "\n",
    "# This is constant as this performed the best, whilst still computing in a reasonable time\n",
    "n_neurons = 500\n",
    "\n",
    "density_range = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "leakage_range = [0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "spectral_radius_range = [0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "gamma_range = [0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "sparsity_range = [0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999]\n",
    "\n",
    "input_weight_type = 'normal'"
   ],
   "id": "e8d9123f64c18db1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
